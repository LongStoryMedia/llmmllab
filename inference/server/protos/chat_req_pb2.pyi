"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
GENERATED CODE - DO NOT EDIT
Generated by schema2code proto generator
"""

import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.message
import message_pb2
import model_parameters_pb2
import typing

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

@typing.final
class ChatReq(google.protobuf.message.Message):
    """ChatReq represents a request to the Ollama API"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    @typing.final
    class Format(google.protobuf.message.Message):
        """The format to return a response in. Format can be json or a JSON schema"""

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        def __init__(
            self,
        ) -> None: ...

    @typing.final
    class ToolsItem(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        def __init__(
            self,
        ) -> None: ...

    MODEL_FIELD_NUMBER: builtins.int
    MESSAGES_FIELD_NUMBER: builtins.int
    STREAM_FIELD_NUMBER: builtins.int
    FORMAT_FIELD_NUMBER: builtins.int
    CONVERSATION_ID_FIELD_NUMBER: builtins.int
    KEEP_ALIVE_FIELD_NUMBER: builtins.int
    OPTIONS_FIELD_NUMBER: builtins.int
    TOOLS_FIELD_NUMBER: builtins.int
    THINK_FIELD_NUMBER: builtins.int
    model: builtins.str
    """Model name, used internally only to set the model name in the request to ollama based on the profile"""
    stream: builtins.bool
    """If true, the response will be streamed back as a series of events"""
    conversation_id: builtins.int
    """UI sends camelCase"""
    keep_alive: builtins.int
    """Controls how long the model will stay loaded into memory"""
    think: builtins.bool
    """If true, the model will think before responding, useful for complex queries"""
    @property
    def messages(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[message_pb2.Message]:
        """Messages to send to the model, each message is a struct with role and content"""

    @property
    def format(self) -> global___ChatReq.Format:
        """The format to return a response in. Format can be json or a JSON schema"""

    @property
    def options(self) -> model_parameters_pb2.ModelParameters:
        """Additional model parameters listed in the documentation for the Modelfile such as temperature"""

    @property
    def tools(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ChatReq.ToolsItem]:
        """Tools to use for the request, if any"""

    def __init__(
        self,
        *,
        model: builtins.str = ...,
        messages: collections.abc.Iterable[message_pb2.Message] | None = ...,
        stream: builtins.bool = ...,
        format: global___ChatReq.Format | None = ...,
        conversation_id: builtins.int = ...,
        keep_alive: builtins.int = ...,
        options: model_parameters_pb2.ModelParameters | None = ...,
        tools: collections.abc.Iterable[global___ChatReq.ToolsItem] | None = ...,
        think: builtins.bool = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["format", b"format", "options", b"options"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["conversation_id", b"conversation_id", "format", b"format", "keep_alive", b"keep_alive", "messages", b"messages", "model", b"model", "options", b"options", "stream", b"stream", "think", b"think", "tools", b"tools"]) -> None: ...

global___ChatReq = ChatReq
